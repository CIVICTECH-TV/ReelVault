use serde::Serialize;
use tauri::command;
use aws_sdk_s3::Client as S3Client;
use crate::commands::aws_auth::{AwsConfig, create_aws_config};
use crate::internal::{InternalError, standardize_error};

/// ReelVaultå›ºå®šãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«è¨­å®š
const REELVAULT_TRANSITION_DAYS: i32 = 1;  // 1æ—¥å¾Œç§»è¡Œ
const REELVAULT_RULE_ID: &str = "ReelVault-Default-Auto-Archive";
const REELVAULT_STORAGE_CLASS: &str = "DEEP_ARCHIVE";



/// ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ãƒãƒªã‚·ãƒ¼è¨­å®šçµæœ
#[derive(Debug, Serialize)]
pub struct LifecyclePolicyResult {
    pub success: bool,
    pub message: String,
    pub rule_id: String,
    pub transition_days: i32,
    pub storage_class: String,
}

/// ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ãƒãƒªã‚·ãƒ¼çŠ¶æ³
#[derive(Debug, Serialize)]
pub struct LifecyclePolicyStatus {
    pub enabled: bool,
    pub rule_id: Option<String>,
    pub transition_days: Option<i32>,
    pub storage_class: Option<String>,
    pub prefix: Option<String>,
    pub error_message: Option<String>,
}

/// ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ãƒ«ãƒ¼ãƒ«è©³ç´°
#[derive(Debug, Serialize)]
pub struct LifecycleRule {
    pub id: String,
    pub status: String,  // "Enabled" or "Disabled"
    pub prefix: Option<String>,
    pub transitions: Vec<LifecycleTransition>,
}

/// ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ç§»è¡Œè¨­å®š
#[derive(Debug, Serialize)]
pub struct LifecycleTransition {
    pub days: i32,
    pub storage_class: String,
}

/// ReelVaultæ¨™æº–ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ãƒãƒªã‚·ãƒ¼ã‚’æœ‰åŠ¹åŒ–
/// 
/// å›ºå®šè¨­å®š:
/// - uploads/é…ä¸‹ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«
/// - 1æ—¥å¾Œã«DEEP_ARCHIVEã«ç§»è¡Œ
/// - 128KBä»¥ä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ï¼ˆAWSåˆ¶é™ï¼‰
#[command]
pub async fn enable_reelvault_lifecycle(config: AwsConfig) -> Result<LifecyclePolicyResult, String> {
    // è¨­å®šã®åŸºæœ¬æ¤œè¨¼
    if config.bucket_name.is_empty() {
        return Err(standardize_error(InternalError::Config("Bucket name is required".to_string())));
    }

    // TODO: AWS SDK for Rustã‚’ä½¿ã£ãŸå®Ÿè£…
    // ç¾åœ¨ã¯ãƒ¢ãƒƒã‚¯å®Ÿè£…
    // 
    // let aws_config = aws_config::load_from_env().await;
    // let s3_client = aws_sdk_s3::Client::new(&aws_config);
    // 
    // let lifecycle_config = create_reelvault_lifecycle_config();
    // let result = s3_client
    //     .put_bucket_lifecycle_configuration()
    //     .bucket(&config.bucket_name)
    //     .lifecycle_configuration(lifecycle_config)
    //     .send()
    //     .await
    //     .map_err(|e| format!("Failed to set lifecycle policy: {}", e))?;

    log::info!("ReelVault lifecycle policy enabled for bucket: {}", config.bucket_name);
    log::info!("Rule: {} days -> {}", REELVAULT_TRANSITION_DAYS, REELVAULT_STORAGE_CLASS);

    Ok(LifecyclePolicyResult {
        success: true,
        message: format!(
            "ReelVault lifecycle policy enabled: {} day(s) -> {}",
            REELVAULT_TRANSITION_DAYS, REELVAULT_STORAGE_CLASS
        ),
        rule_id: REELVAULT_RULE_ID.to_string(),
        transition_days: REELVAULT_TRANSITION_DAYS,
        storage_class: REELVAULT_STORAGE_CLASS.to_string(),
    })
}

/// ç¾åœ¨ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ãƒãƒªã‚·ãƒ¼è¨­å®šçŠ¶æ³ã‚’å–å¾—
#[command]
pub async fn get_lifecycle_status(config: AwsConfig) -> Result<LifecyclePolicyStatus, String> {
    // è¨­å®šã®åŸºæœ¬æ¤œè¨¼
    if config.bucket_name.is_empty() {
        return Err(standardize_error(InternalError::Config("Bucket name is required".to_string())));
    }

    use aws_config::{Region, BehaviorVersion};
    use aws_credential_types::Credentials;
    use aws_sdk_s3::Client as S3Client;

    let region = Region::new(config.region.clone());
    let mut config_builder = aws_config::defaults(BehaviorVersion::latest())
        .region(region);

    // èªè¨¼æƒ…å ±ã‚’è¨­å®š
    let creds = Credentials::new(
        &config.access_key_id,
        &config.secret_access_key,
        None,
        None,
        "manual",
    );
    config_builder = config_builder.credentials_provider(creds);
    let aws_config = config_builder.load().await;

    let s3_client = S3Client::new(&aws_config);

    log::info!("Lifecycle status check for bucket: {}", config.bucket_name);

    // ã¾ãšãƒã‚±ãƒƒãƒˆã®å­˜åœ¨ç¢ºèª
    log::debug!("Checking bucket existence: {}", config.bucket_name);
    match s3_client.head_bucket().bucket(&config.bucket_name).send().await {
        Ok(_) => {
            log::debug!("Bucket exists and accessible: {}", config.bucket_name);
        }
        Err(e) => {
            log::error!("Bucket access failed: {}", e);
            return Ok(LifecyclePolicyStatus {
                enabled: false,
                rule_id: None,
                transition_days: None,
                storage_class: None,
                prefix: None,
                error_message: Some(format!("ãƒã‚±ãƒƒãƒˆã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼: {}", e)),
            });
        }
    }

    // ãƒã‚±ãƒƒãƒˆã®ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª
    log::debug!("Checking bucket region: {}", config.bucket_name);
    match s3_client.get_bucket_location().bucket(&config.bucket_name).send().await {
        Ok(response) => {
            let bucket_region = response.location_constraint().map(|r| r.as_str()).unwrap_or("us-east-1");
            log::debug!("Bucket region: {}", bucket_region);
        }
        Err(e) => {
            log::warn!("Failed to get bucket region (non-fatal): {}", e);
        }
    }

    // ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«è¨­å®šã‚’å–å¾—
    log::debug!("Calling get_bucket_lifecycle_configuration for bucket: {}", config.bucket_name);
    match s3_client
        .get_bucket_lifecycle_configuration()
        .bucket(&config.bucket_name)
        .send()
        .await
    {
        Ok(response) => {
            log::debug!("Successfully retrieved lifecycle configuration, rules count: {}", response.rules().len());
            // ReelVaultãƒ«ãƒ¼ãƒ«ã‚’æ¤œç´¢
            for rule in response.rules() {
                if rule.id().unwrap_or("") == REELVAULT_RULE_ID {
                    // ReelVaultãƒ«ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆ
                    let enabled = rule.status() == &aws_sdk_s3::types::ExpirationStatus::Enabled;
                    
                    let (transition_days, storage_class) = if !rule.transitions().is_empty() {
                        let transitions = rule.transitions();
                        if let Some(first_transition) = transitions.first() {
                            (
                                first_transition.days().unwrap_or(0),
                                first_transition.storage_class().map(|sc| match sc {
                                    aws_sdk_s3::types::TransitionStorageClass::DeepArchive => "DEEP_ARCHIVE",
                                    aws_sdk_s3::types::TransitionStorageClass::Glacier => "GLACIER",
                                    aws_sdk_s3::types::TransitionStorageClass::StandardIa => "STANDARD_IA",
                                    _ => "UNKNOWN",
                                }).unwrap_or("UNKNOWN").to_string()
                            )
                        } else {
                            (0, "NONE".to_string())
                        }
                    } else {
                        (0, "NONE".to_string())
                    };

                    let prefix = rule.filter()
                        .and_then(|f| f.prefix())
                        .map(|p| p.to_string());

                    return Ok(LifecyclePolicyStatus {
                        enabled,
                        rule_id: Some(REELVAULT_RULE_ID.to_string()),
                        transition_days: Some(transition_days),
                        storage_class: Some(storage_class),
                        prefix,
                        error_message: None,
                    });
                }
            }
            
            // ReelVaultãƒ«ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
            log::debug!("ReelVault lifecycle rule not found in {} rules", response.rules().len());
            Ok(LifecyclePolicyStatus {
                enabled: false,
                rule_id: None,
                transition_days: None,
                storage_class: None,
                prefix: None,
                error_message: Some("ReelVault lifecycle rule not found".to_string()),
            })
        }
        Err(e) => {
            log::error!("Failed to get lifecycle configuration: {}", e);
            Ok(LifecyclePolicyStatus {
                enabled: false,
                rule_id: None,
                transition_days: None,
                storage_class: None,
                prefix: None,
                error_message: Some(format!("ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«è¨­å®šå–å¾—ã‚¨ãƒ©ãƒ¼: {}", e)),
            })
        }
    }
}

/// ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ãƒãƒªã‚·ãƒ¼ã‚’ç„¡åŠ¹åŒ–
#[command]
pub async fn disable_lifecycle_policy(config: AwsConfig) -> Result<LifecyclePolicyResult, String> {
    // è¨­å®šã®åŸºæœ¬æ¤œè¨¼
    if config.bucket_name.is_empty() {
        return Err(standardize_error(InternalError::Config("Bucket name is required".to_string())));
    }

    // TODO: AWS SDK for Rustã‚’ä½¿ã£ãŸå®Ÿè£…
    // ç¾åœ¨ã¯ãƒ¢ãƒƒã‚¯å®Ÿè£…
    // 
    // let aws_config = aws_config::load_from_env().await;
    // let s3_client = aws_sdk_s3::Client::new(&aws_config);
    // 
    // let result = s3_client
    //     .delete_bucket_lifecycle()
    //     .bucket(&config.bucket_name)
    //     .send()
    //     .await
    //     .map_err(|e| format!("Failed to disable lifecycle policy: {}", e))?;

    log::info!("ReelVault lifecycle policy disabled for bucket: {}", config.bucket_name);

    Ok(LifecyclePolicyResult {
        success: true,
        message: "ReelVault lifecycle policy disabled".to_string(),
        rule_id: REELVAULT_RULE_ID.to_string(),
        transition_days: 0,
        storage_class: "STANDARD".to_string(),
    })
}

/// å…¨ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ãƒ«ãƒ¼ãƒ«ä¸€è¦§ã‚’å–å¾—ï¼ˆPhase 2æº–å‚™ï¼‰
#[command]
pub async fn list_lifecycle_rules(config: AwsConfig) -> Result<Vec<LifecycleRule>, String> {
    // è¨­å®šã®åŸºæœ¬æ¤œè¨¼
    if config.bucket_name.is_empty() {
        return Err(standardize_error(InternalError::Config("Bucket name is required".to_string())));
    }

    use aws_config::{Region, BehaviorVersion};
    use aws_credential_types::Credentials;

    let region = Region::new(config.region.clone());
    let mut config_builder = aws_config::defaults(BehaviorVersion::latest())
        .region(region);

    // èªè¨¼æƒ…å ±ã‚’è¨­å®š
    let creds = Credentials::new(
        &config.access_key_id,
        &config.secret_access_key,
        None,
        None,
        "manual",
    );
    config_builder = config_builder.credentials_provider(creds);
    let aws_config = config_builder.load().await;

    let s3_client = S3Client::new(&aws_config);

    match s3_client
        .get_bucket_lifecycle_configuration()
        .bucket(&config.bucket_name)
        .send()
        .await
    {
        Ok(response) => {
            let mut rules = Vec::new();
            for rule in response.rules() {
                let transitions: Vec<LifecycleTransition> = rule.transitions()
                    .iter()
                    .map(|t| LifecycleTransition {
                        days: t.days().unwrap_or(0),
                        storage_class: t.storage_class().map(|sc| match sc {
                            aws_sdk_s3::types::TransitionStorageClass::DeepArchive => "DEEP_ARCHIVE",
                            aws_sdk_s3::types::TransitionStorageClass::Glacier => "GLACIER",
                            aws_sdk_s3::types::TransitionStorageClass::StandardIa => "STANDARD_IA",
                            _ => "UNKNOWN",
                        }).unwrap_or("UNKNOWN").to_string(),
                    })
                    .collect();

                rules.push(LifecycleRule {
                    id: rule.id().unwrap_or("").to_string(),
                    status: match rule.status() {
                        aws_sdk_s3::types::ExpirationStatus::Enabled => "Enabled",
                        aws_sdk_s3::types::ExpirationStatus::Disabled => "Disabled",
                        _ => "Unknown",
                    }.to_string(),
                    prefix: rule.filter()
                        .and_then(|f| f.prefix())
                        .map(|p| p.to_string()),
                    transitions,
                });
            }
            Ok(rules)
        }
        Err(e) => {
            log::error!("Failed to get lifecycle rules: {}", e);
            Err(standardize_error(InternalError::S3(format!("Failed to get lifecycle rules: {}", e))))
        }
    }
}

/// ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«è¨­å®šã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
#[command]
pub async fn validate_lifecycle_config(config: AwsConfig) -> Result<bool, String> {
    // åŸºæœ¬çš„ãªãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    if config.bucket_name.is_empty() {
        return Err(standardize_error(InternalError::Config("Bucket name is required".to_string())));
    }

    if config.access_key_id.is_empty() {
        return Err(standardize_error(InternalError::Config("Access Key ID is required".to_string())));
    }

    if config.secret_access_key.is_empty() {
        return Err(standardize_error(InternalError::Config("Secret Access Key is required".to_string())));
    }

    if config.region.is_empty() {
        return Err(standardize_error(InternalError::Config("Region is required".to_string())));
    }

    // TODO: AWSæ¥ç¶šãƒ†ã‚¹ãƒˆã¨ãƒã‚±ãƒƒãƒˆæ¨©é™ãƒã‚§ãƒƒã‚¯
    // let aws_config = aws_config::load_from_env().await;
    // let s3_client = aws_sdk_s3::Client::new(&aws_config);
    // 
    // // ãƒã‚±ãƒƒãƒˆå­˜åœ¨ãƒã‚§ãƒƒã‚¯
    // s3_client.head_bucket().bucket(&config.bucket_name).send().await
    //     .map_err(|e| format!("Bucket access failed: {}", e))?;
    // 
    // // ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«è¨­å®šæ¨©é™ãƒã‚§ãƒƒã‚¯
    // let test_config = create_reelvault_lifecycle_config();
    // s3_client
    //     .put_bucket_lifecycle_configuration()
    //     .bucket(&config.bucket_name)
    //     .lifecycle_configuration(test_config)
    //     .send()
    //     .await
    //     .map_err(|e| format!("Lifecycle permission denied: {}", e))?;

    log::info!("Lifecycle config validation completed for bucket: {}", config.bucket_name);

    Ok(true)
}

#[derive(serde::Serialize)]
pub struct UploadReadinessResult {
    pub safe: bool,
    pub message: String,
    pub lifecycle_healthy: bool,
}

/// ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‰ã®å®‰å…¨ç¢ºèª
#[command]
pub async fn check_upload_readiness(config: AwsConfig) -> Result<UploadReadinessResult, String> {
    log::info!("Checking upload readiness for bucket: {}", config.bucket_name);

    // åŸºæœ¬è¨­å®šãƒã‚§ãƒƒã‚¯
    if config.bucket_name.is_empty() {
        return Ok(UploadReadinessResult {
            safe: false,
            message: "S3ãƒã‚±ãƒƒãƒˆåãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“".to_string(),
            lifecycle_healthy: false,
        });
    }

    if config.access_key_id.is_empty() || config.secret_access_key.is_empty() {
        return Ok(UploadReadinessResult {
            safe: false,
            message: "AWSèªè¨¼æƒ…å ±ãŒä¸å®Œå…¨ã§ã™".to_string(),
            lifecycle_healthy: false,
        });
    }

    // AWSè¨­å®šã‚’ä½œæˆ
    let aws_config = match create_aws_config(&config).await {
        Ok(cfg) => cfg,
        Err(e) => {
            log::error!("Failed to create AWS config: {}", e);
            return Ok(UploadReadinessResult {
                safe: false,
                message: format!("AWSè¨­å®šã®ä½œæˆã«å¤±æ•—: {}", e),
                lifecycle_healthy: false,
            });
        }
    };

    let s3_client = S3Client::new(&aws_config);

    // 1. ãƒã‚±ãƒƒãƒˆã‚¢ã‚¯ã‚»ã‚¹ç¢ºèª
    match s3_client.head_bucket()
        .bucket(&config.bucket_name)
        .send()
        .await 
    {
        Ok(_) => {
            log::info!("âœ… Bucket access confirmed: {}", config.bucket_name);
        }
        Err(e) => {
            log::warn!("âŒ Bucket access check failed: {:?}", e);
            return Ok(UploadReadinessResult {
                safe: false,
                message: format!("ãƒã‚±ãƒƒãƒˆã€Œ{}ã€ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“: {}", config.bucket_name, e),
                lifecycle_healthy: false,
            });
        }
    }

    // 2. ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«è¨­å®šç¢ºèª
    let lifecycle_healthy = match s3_client.get_bucket_lifecycle_configuration()
        .bucket(&config.bucket_name)
        .send()
        .await 
    {
        Ok(response) => {
            // ReelVaultãƒ«ãƒ¼ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                         let rules = response.rules();
            let reelvault_rule = rules.iter().find(|rule| {
                rule.id().map_or(false, |id| id == REELVAULT_RULE_ID)
            });

            if let Some(rule) = reelvault_rule {
                // ãƒ«ãƒ¼ãƒ«ãŒEnabledã‹ãƒã‚§ãƒƒã‚¯
                let enabled = rule.status() == &aws_sdk_s3::types::ExpirationStatus::Enabled;
                log::info!("ReelVault lifecycle rule found, enabled: {}", enabled);
                enabled
            } else {
                log::warn!("ReelVault lifecycle rule not found");
                false
            }
        },
        Err(e) => {
            // ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’ãƒã‚§ãƒƒã‚¯
            let error_string = e.to_string();
            log::warn!("Error checking lifecycle configuration: {}", error_string);
            
            if error_string.contains("NoSuchLifecycleConfiguration") {
                log::info!("No lifecycle configuration found for bucket: {} - upload not safe", config.bucket_name);
                false
            } else {
                log::error!("Unexpected lifecycle check error: {:?}", e);
                false
            }
        }
    };

    // 3. çµæœåˆ¤å®š
    if lifecycle_healthy {
        log::info!("âœ… Upload readiness check passed for bucket: {}", config.bucket_name);
        Ok(UploadReadinessResult {
            safe: true,
            message: "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æº–å‚™å®Œäº†ã€‚ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«è¨­å®šã‚‚æ­£å¸¸ã§ã™ã€‚".to_string(),
            lifecycle_healthy: true,
        })
    } else {
        log::warn!("âš ï¸ Upload readiness check failed - lifecycle not configured for bucket: {}", config.bucket_name);
        Ok(UploadReadinessResult {
            safe: false,
            message: format!(
                "ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«è¨­å®šã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ãƒã‚±ãƒƒãƒˆã€Œ{}ã€ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ãƒãƒªã‚·ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚AWSèªè¨¼ã‚¿ãƒ–ã§ã€ŒğŸ”„ ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«å†è¨­å®šã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚", 
                config.bucket_name
            ),
            lifecycle_healthy: false,
        })
    }
}

// å†…éƒ¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼ˆå°†æ¥ã®AWS SDKå®Ÿè£…ç”¨ï¼‰

// ReelVaultå›ºå®šãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«è¨­å®šã‚’ç”Ÿæˆ
// fn create_reelvault_lifecycle_config() -> LifecycleConfiguration {
//     use aws_sdk_s3::types::{
//         LifecycleConfiguration, LifecycleRule, LifecycleRuleFilter,
//         Transition, BucketLifecycleConfigurationStatus, TransitionStorageClass
//     };
//     
//     let transition = Transition::builder()
//         .days(REELVAULT_TRANSITION_DAYS)
//         .storage_class(TransitionStorageClass::DeepArchive)
//         .build();
//     
//     let rule = LifecycleRule::builder()
//         .id(REELVAULT_RULE_ID)
//         .status(BucketLifecycleConfigurationStatus::Enabled)
//         .filter(LifecycleRuleFilter::Prefix("uploads/".to_string()))
//         .transitions(transition)
//         .build();
//     
//     LifecycleConfiguration::builder()
//         .rules(rule)
//         .build()
// }

// ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ãƒ«ãƒ¼ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹
// fn parse_lifecycle_rule(rule: LifecycleRule) -> LifecyclePolicyStatus {
//     let mut transition_days = None;
//     let mut storage_class = None;
//     
//     if let Some(transitions) = rule.transitions {
//         if let Some(first_transition) = transitions.first() {
//             transition_days = first_transition.days;
//             storage_class = first_transition.storage_class.as_ref().map(|s| s.to_string());
//         }
//     }
//     
//     let prefix = match rule.filter {
//         Some(LifecycleRuleFilter::Prefix(p)) => Some(p),
//         _ => None,
//     };
//     
//     LifecyclePolicyStatus {
//         enabled: rule.status == Some(BucketLifecycleConfigurationStatus::Enabled),
//         rule_id: rule.id,
//         transition_days,
//         storage_class,
//         prefix,
//         error_message: None,
//     }
// } 